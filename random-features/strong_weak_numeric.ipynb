{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical experiments for the RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import defaultdict, OrderedDict\n",
    "import matplotlib\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import sys\n",
    "import random\n",
    "import copy\n",
    "import sklearn\n",
    "import skimage\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import itertools\n",
    "sys.path.append('.')\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 12\n",
    "plt.rc('font',       size=2*MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('axes',  titlesize=2*MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes',  labelsize=2*MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=2*SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=2*SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=2*SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure',titlesize=2*BIGGER_SIZE)  # fontsize of the figure title\n",
    "plt.rc(\"lines\", linewidth=3.0)\n",
    "plt.rcParams[\"savefig.dpi\"] = 500\n",
    "cmap = plt.get_cmap('Spectral_r')\n",
    "\n",
    "savedir = './figs/'\n",
    "datadir = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_product(d):\n",
    "    keys = d.keys()\n",
    "    for element in itertools.product(*d.values()):\n",
    "        yield dict(zip(keys, element))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_orthogonal(D, P, eps=1, max_iter=100):\n",
    "    from scipy.stats import ortho_group\n",
    "    U = torch.from_numpy(ortho_group.rvs(P)).float()\n",
    "    V = torch.from_numpy(ortho_group.rvs(D)).float()\n",
    "    S = torch.zeros((P, D))\n",
    "    for i in range(min(D,P)):\n",
    "        S[i,i] = D**0.5 * max(1, (D/P)**0.5)\n",
    "    points = U @ S @ V\n",
    "    return points\n",
    "\n",
    "def generate_rfs(K,D,P,init='gaussian'):\n",
    "    rfs = []\n",
    "    for k in range(K):\n",
    "        if init=='gaussian':\n",
    "            rf = torch.randn((D,P))\n",
    "        elif init=='orthogonal':\n",
    "            rf = generate_orthogonal(D, P).t()\n",
    "        elif init=='even':\n",
    "            rf = generate_even(D, P, lr=10, eps=.0, max_iter=10).t()\n",
    "        rfs.append(rf)\n",
    "    rf = torch.stack(rfs)\n",
    "    return rf\n",
    "\n",
    "\n",
    "def get_dataset(dataset, D=None, N_train=10000, N_test=10000, norm=1, resize_method='PCA', cov=None):\n",
    "    \n",
    "    if dataset=='random':\n",
    "        if cov is None:\n",
    "            tr_data = torch.randn((N_train,D))\n",
    "            te_data = torch.randn((N_test,D))\n",
    "        else:\n",
    "            tr_data = torch.from_numpy(np.random.multivariate_normal(mean=np.zeros(D),cov=cov,size=(N_train))).float()\n",
    "            te_data = torch.from_numpy(np.random.multivariate_normal(mean=np.zeros(D),cov=cov,size=(N_test ))).float()\n",
    "\n",
    "    else:\n",
    "        import utils\n",
    "        tr_data, te_data, input_size, output_size = utils.get_data(dataset, d=D, n=N_train)\n",
    "        if D is not None:\n",
    "            if resize_method=='PCA':\n",
    "                tr_data, te_data = utils.get_pca(tr_data, te_data, D, normalized=True)\n",
    "            else:\n",
    "                tr_data, te_data = utils.resize_data(tr_data, te_data, D)\n",
    "        tr_data = tr_data.data.view(tr_data.data.size(0), -1)\n",
    "        te_data = te_data.data.view(te_data.data.size(0), -1)\n",
    "                \n",
    "    return tr_data, te_data\n",
    "    \n",
    "def get_act(actname):\n",
    "    if actname=='relu':\n",
    "        return lambda x : F.relu(x)\n",
    "    elif actname=='abs':\n",
    "        return lambda x : abs(x)\n",
    "    elif actname=='tanh':\n",
    "        return lambda x : torch.tanh(x)\n",
    "    elif actname=='linear':\n",
    "        return lambda x : x\n",
    "    elif type(actname)!=str: \n",
    "        alpha=actname\n",
    "        return lambda x : (F.relu(x) + alpha*F.relu(-x) - (1+alpha)/np.sqrt(2*np.pi))/np.sqrt((1+alpha**2)/2 - (1+alpha)**2/(2*np.pi))\n",
    "    else:\n",
    "        raise NotImplemented\n",
    "        \n",
    "def test(k, act, rf, a, te_data, y_test, task='regression'):\n",
    "            \n",
    "    K,D,P=rf.size()\n",
    "\n",
    "    errors = []\n",
    "    for ik in range(int(K/k)):\n",
    "        y_pred = torch.einsum('knp,kp->kn',(act(te_data @ rf[k*ik:k*(ik+1)] / D**0.5) / D**0.5, a[k*ik:k*(ik+1)]))\n",
    "        if task == 'classification':\n",
    "            y_pred = y_pred.sign()\n",
    "        error = (y_pred-y_test).mean(0).pow(2).mean() / 2\n",
    "        if task == 'classification':\n",
    "            error /= 2\n",
    "        errors.append(error)\n",
    "\n",
    "    return np.mean(errors), np.std(errors)   \n",
    "\n",
    "def calc_norms(rf, a, X):\n",
    "    K, D, P = rf.size()\n",
    "    N, D = X.size()\n",
    "    norms_curr = []\n",
    "    for k in range(K):\n",
    "        original = a[k]\n",
    "        norm = original.norm().mean().item()/P\n",
    "        subspace = X @ rf[k] / D\n",
    "        subspace = subspace / subspace.norm(dim=-1, keepdim=True)\n",
    "        projected = original @ subspace.t() @ torch.pinverse(subspace @ subspace.t()) @ subspace / max(1, N/P)\n",
    "        orth = original-projected\n",
    "        norm         = original .norm().item()/P\n",
    "        norm_proj    = projected.norm().item()/P\n",
    "        norm_orth    = orth     .norm().item()/P\n",
    "        norms_curr.append([norm, norm_proj, norm_orth])\n",
    "    norms = np.mean(np.array(norms_curr), axis=0)\n",
    "    return norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rf(args):\n",
    "    \n",
    "    D, K = args['D'], args['K']\n",
    "    rx, rb, rphi = args['rx'], args['rb'], args['rphi']\n",
    "\n",
    "    cov = torch.zeros((D,D))\n",
    "    ds = np.array([1/rphi, 1-1/rphi])\n",
    "    cs = np.array([rx/(rx*ds[0]+ds[1]), 1/(rx*ds[0]+ds[1])])\n",
    "    betas = np.array([rb/(rb*ds[0]*cs[0]+ds[1]*cs[1]), 1/(rb*ds[0]*cs[0]+ds[1]*cs[1])])\n",
    "\n",
    "    for i in range(D):\n",
    "        if i < int(D/rphi) : \n",
    "            cov[i,i] = cs[0]\n",
    "        else : \n",
    "            cov[i,i] = cs[1]\n",
    "    beta = torch.zeros(D)\n",
    "    beta[:int(D/rphi)] = betas[0]**.5 * torch.randn(int(D/rphi))\n",
    "    beta[int(D/rphi):] = betas[1]**.5 * torch.randn(D-int(D/rphi))\n",
    "    \n",
    "    teacher = lambda x : x @ beta / D**0.5 \n",
    "\n",
    "    tr_data, te_data = get_dataset(args['dataset'], D, N_train=int(D*max(args['Psi2_list'])), N_test=args['N_test'], cov=cov, resize_method='PCA')\n",
    "    act = get_act(args['actname'])\n",
    "    \n",
    "    tr_errors = []\n",
    "    tr_errors_std = []\n",
    "    te_errors = []\n",
    "    te_errors_std = []\n",
    "    te_errors_ens = []\n",
    "            \n",
    "    y_test = teacher(te_data)\n",
    "    if args['task']=='classification': y_test = y_test.sign()\n",
    "            \n",
    "    for i, Psi1 in enumerate(args['Psi1_list']):\n",
    "        for j, Psi2 in enumerate(args['Psi2_list']):\n",
    "\n",
    "            P = int(D * Psi1)\n",
    "            N = int(D * Psi2)\n",
    "            rf = generate_rfs(K,D,P,init='gaussian')\n",
    "\n",
    "            X = tr_data[:N]\n",
    "            y = teacher(X) \n",
    "            if args['task']=='classification': \n",
    "                y = y.sign()\n",
    "                y *= ((np.random.uniform(0,1,len(y))>args['tau']).astype(int)-.5)*2\n",
    "                y = y.float()\n",
    "            else: y += args['tau']**.5 * torch.randn((N,))\n",
    "\n",
    "            a = torch.empty((K,P))\n",
    "\n",
    "            for k in range(K):\n",
    "                Z = act(X @ rf[k] / D**0.5) / D**0.5\n",
    "                a[k] = y @ Z @ torch.from_numpy(np.linalg.pinv((Z.t() @ Z + .5 * args['lam'] * torch.eye(P)).numpy()))\n",
    "\n",
    "            tr_error, tr_error_std         = test(1, act, rf, a, X, y           , task=args['task'])\n",
    "            te_error, te_error_std         = test(1, act, rf, a, te_data, y_test, task=args['task'])\n",
    "            te_error_ens, te_error_ens_std = test(K, act, rf, a, te_data, y_test, task=args['task'])\n",
    "\n",
    "            tr_errors.append(tr_error)\n",
    "            tr_errors_std.append(tr_error_std)\n",
    "            te_errors.append(te_error)\n",
    "            te_errors_std.append(te_error_std)\n",
    "            te_errors_ens.append(te_error_ens)\n",
    "            \n",
    "        \n",
    "    run = {'args':copy.deepcopy(args),\n",
    "           'tr_error':tr_errors,\n",
    "           'tr_error_std':tr_errors_std,\n",
    "           'te_error':te_errors,\n",
    "           'te_error_std':te_errors_std,\n",
    "           'te_error_ens':te_errors_ens}\n",
    "    return run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train both layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nn(args):\n",
    "    \n",
    "    D, K = args['D'], args['K']\n",
    "    rx, rb, rphi = args['rx'], args['rb'], args['rphi']\n",
    "\n",
    "    cov = torch.zeros((D,D))\n",
    "    ds = np.array([1/rphi, 1-1/rphi])\n",
    "    cs = np.array([rx/(rx*ds[0]+ds[1]), 1/(rx*ds[0]+ds[1])])\n",
    "    betas = np.array([rb/(rb*ds[0]*cs[0]+ds[1]*cs[1]), 1/(rb*ds[0]*cs[0]+ds[1]*cs[1])])\n",
    "\n",
    "    for i in range(D):\n",
    "        if i < int(D/rphi) : \n",
    "            cov[i,i] = cs[0]\n",
    "        else : \n",
    "            cov[i,i] = cs[1]\n",
    "    beta = torch.zeros(D)\n",
    "    beta[:int(D/rphi)] = betas[0]**.5 * torch.randn(int(D/rphi))\n",
    "    beta[int(D/rphi):] = betas[1]**.5 * torch.randn(D-int(D/rphi))\n",
    "    \n",
    "    teacher = lambda x : x @ beta / D**0.5 \n",
    "\n",
    "    tr_data, te_data = get_dataset(args['dataset'], D, N_train=int(D*max(args['Psi2_list'])), N_test=args['N_test'], cov=cov)\n",
    "    act = get_act(args['actname'])\n",
    "    \n",
    "    tr_errors = []\n",
    "    te_errors = []\n",
    "    te_errors_std = []\n",
    "            \n",
    "    y_test = teacher(te_data)\n",
    "            \n",
    "    for i, Psi1 in enumerate(args['Psi1_list']):\n",
    "        for j, Psi2 in enumerate(args['Psi2_list']):\n",
    "            #print(i,j)\n",
    "\n",
    "            P = int(D * Psi1)\n",
    "            N = int(D * Psi2)\n",
    "\n",
    "            X = tr_data[:N]\n",
    "            y = teacher(X) + args['tau']**.5 * torch.randn((N,))\n",
    "            \n",
    "            tmp = []\n",
    "            for k in range(args['K']):\n",
    "                model = MLPRegressor(activation=args['actname'], hidden_layer_sizes=[P], solver='adam', alpha=0, learning_rate='constant', max_iter=500)\n",
    "                model.fit(X,y)\n",
    "                y_pred = model.predict(te_data)\n",
    "                y_true = teacher(te_data)\n",
    "                te_error = np.mean((y_pred-y_true.numpy())**2)\n",
    "                tmp.append(te_error)\n",
    "                \n",
    "            te_errors.append(np.mean(tmp))            \n",
    "            te_errors_std.append(np.std(tmp))            \n",
    "        \n",
    "    run = {'args':copy.deepcopy(args),\n",
    "           'te_error':te_errors,\n",
    "           'te_error_std':te_errors}\n",
    "    return run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'D' :150,\n",
    "    'Psi2_list'  : [1],\n",
    "    'Psi1_list' : np.logspace(-1,1,19),\n",
    "    'N_test' : 5000,\n",
    "    'K' : 50,\n",
    "    'lam' : 1e-3,\n",
    "    'actname': 'relu',\n",
    "    'dataset' : 'random',\n",
    "    'rphi': 10}\n",
    "\n",
    "model = \"rf\"\n",
    "\n",
    "constraints = {'tau':[0.3],\n",
    "       'task':['classification']}\n",
    "\n",
    "for cons in dict_product(constraints):\n",
    "    args['tau']=cons['tau']\n",
    "    args['task']=cons['task']\n",
    "    runs = {}\n",
    "    for rx in [1,100]:\n",
    "        for irb, rb in enumerate([0.01,100]):\n",
    "            if rx==1 and irb>0: continue\n",
    "            args['rx'], args['rb'] = rx, rb\n",
    "            if model==\"nn\":\n",
    "                run = run_nn(args)\n",
    "            elif model==\"rf\":\n",
    "                run = run_rf(args)\n",
    "            runs[(rx,rb)]=run\n",
    "    if len(args['Psi1_list'])>1:\n",
    "        title = datadir+'parameter_wise_{}_{}.pyT'.format(args['task'], args['tau'])\n",
    "    else:\n",
    "        title = datadir+   'sample_wise_{}_{}.pyT'.format(args['task'], args['tau'])\n",
    "    torch.save(runs, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,2,figsize=(9,4))\n",
    "for i, dataset in enumerate(['CIFAR10','MNIST']):\n",
    "    tr_data, te_data = get_dataset(dataset, D=64, N_train=10000, N_test=10000, resize_method='resize')\n",
    "    data = tr_data\n",
    "    cov = (data-data.mean(dim=0)).t() @ (data-data.mean(dim=0)) / len(data)\n",
    "    spectrum = torch.symeig(cov)[0]\n",
    "    sigma = spectrum/spectrum.sum()\n",
    "    entropy = -torch.sum(sigma * torch.log10(sigma))\n",
    "    erank = 10**(entropy)\n",
    "    print(erank)\n",
    "    hist = axarr[i].hist(spectrum, alpha=.5, bins=20)\n",
    "    axarr[i].set_title('{0}, Effective rank = {1:.1f}'.format(dataset, erank.item()))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "ds, cs = hist[0], hist[1]\n",
    "print(ds,cs)\n",
    "ds /= ds.sum()\n",
    "cs = (cs[1:]+cs[:-1])/2\n",
    "torch.save((ds, cs), datadir+'histogram.pyT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'D' :100,\n",
    "    'Psi1_list'  : [2],\n",
    "    'Psi2_list' : np.logspace(-1,1,19),\n",
    "    'N_test' : 1000,\n",
    "    'K' : 5,\n",
    "    'lam' : 1e-3,\n",
    "    'actname': 'tanh',\n",
    "    'dataset' : 'CIFAR10',\n",
    "    'd': 1,\n",
    "    'c': [1,1],\n",
    "    'b': [1,1]}\n",
    "\n",
    "model = \"rf\"\n",
    "\n",
    "for tau in [0,.1]:\n",
    "    runs = []\n",
    "    args['tau']=tau\n",
    "        \n",
    "    if model==\"nn\":\n",
    "        run = run_nn(args)\n",
    "    elif model==\"rf\":\n",
    "        run = run_rf(args)\n",
    "    runs.append(run)\n",
    "        \n",
    "    if len(args['Psi1_list'])>1:\n",
    "        title = datadir+'parameter_wise_{}_{}_{}.pyT'.format(model, tau, args['dataset'])\n",
    "    else: \n",
    "        title = datadir+   'sample_wise_{}_{}_{}.pyT'.format(model, tau, args['dataset'])\n",
    "    torch.save(runs, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'rf'\n",
    "plot_type = 'sample_wise'\n",
    "\n",
    "if plot_type not in ['parameter_wise', 'sample_wise']:\n",
    "    raise \n",
    "    \n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "for tau in [0, .1]:\n",
    "    runs = torch.load(datadir+plot_type+'_{}_{}_CIFAR10.pyT'.format(model, tau))\n",
    "    for i,run in enumerate(runs):\n",
    "        args=run['args']\n",
    "        x = args['Psi1_list'] if plot_type=='parameter_wise' else args['Psi2_list']\n",
    "        plt.plot(x, run['te_errors'], label=r'$\\Delta={}$'.format(args['tau']))\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "#plt.axvline(x=args['Psi1_list'Â£], color='grey', label='N=P', ls='--')\n",
    "if plot_type == 'parameter_wise':\n",
    "    plt.xlabel('$p/d$')\n",
    "else: \n",
    "    plt.xlabel('$m/d$')\n",
    "\n",
    "plt.ylabel('Test loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(savedir+plot_type+'_{}_{}.pdf'.format(model,tau), bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
